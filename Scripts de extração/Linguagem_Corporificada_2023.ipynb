{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qIxtlC5V2r"
      },
      "source": [
        "# 1. Montar o Google Drive\n",
        "Neste momento, precisamos ligar o Drive ao Notebook, de modo com que possamos acessar os arquivos do Drive aqui. Ao executar a função, uma janela será aberta para que você acesse a conta Google na qual você está usando o Google Colab, que é a mesma a qual você utilizará o Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxbpvJPb4FdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ef9524-0a23-454e-ed36-58535dbad243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LmSRA1UjqAg"
      },
      "source": [
        "# 2. Instalar as bibliotecas\n",
        "Neste momento, são instaladas e importadas todas as bibliotecas e componentes necessários para funcionamento dos códigos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5FkjndkjsYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4214a0-0841-41c4-8eef-9b4b81f2d111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting spacy-lookups-data\n",
            "  Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy-lookups-data) (71.0.4)\n",
            "Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl (98.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spacy-lookups-data\n",
            "Successfully installed spacy-lookups-data-1.0.5\n",
            "Collecting pt-core-news-lg==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.7.0/pt_core_news_lg-3.7.0-py3-none-any.whl (568.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-lg==3.7.0) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.23.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-lg\n",
            "Successfully installed pt-core-news-lg-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (1.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n",
        "\n",
        "!pip install -U spacy-lookups-data\n",
        "\n",
        "!python -m spacy download pt_core_news_lg\n",
        "\n",
        "!pip install pandas\n",
        "\n",
        "!pip install wasabi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obP500rcr9dp"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_lg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ygsElQJ5rmF"
      },
      "source": [
        "# 3. Carregar os arquivos .txt do Google Drive\n",
        "Para tanto, é necessário:\n",
        "- Criar uma pasta no Google Drive contendo os arquivos .txt que você deseja processar.\n",
        "- Determinar o caminho para a pasta no Google Drive. Por exemplo, se a pasta estiver localizada em \"Meu Drive/Minha Pasta\", o caminho será \"/content/drive/MyDrive/Minha Pasta\".\n",
        "- Execute o seguinte código para carregar os arquivos .txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXV_yzJzUAej"
      },
      "outputs": [],
      "source": [
        "nomes_arq = !ls '/content/drive/MyDrive/LinguagemCorporificada2023/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZQHYNtveZxB"
      },
      "source": [
        "# 4. Extração de informação dos arquivos\n",
        "O seguinte código é utilizado para a extração de informações presentes na própria entrevista, como nome do arquivo, que é o que desejamos, uma vez que o nome possui informações sobre o falante (gênero, idade, deslocamento e tempo no curso) e sobre a amostra (São Cristóvão 2019, São Cristóvão 2020 ou Itabaiana)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75g1SGAKnBO0"
      },
      "source": [
        "Código para extrair informações dos nomes das entrevistas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCZenVZInJ82"
      },
      "outputs": [],
      "source": [
        "def extrai_num_ent(nome_arquivo):\n",
        "    num_ent = nome_arquivo[0:65]\n",
        "    return num_ent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rzRtV_5e7Kw"
      },
      "source": [
        "# 5. Extração dos fenômenos\n",
        "A partir daqui, lidamos com a extração das ocorrências dos fenômenos, cada um dos fenômenos isoladamente. Para tanto, esta seção apresenta:\n",
        "- Código de busca e classificação\n",
        "- Armazenamento dos resultados em arquivo .xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DX_AjPE2VCO"
      },
      "source": [
        "## 5.1 Determinantes possessivos antecedendo nomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysSAXqVEzRNd"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from wasabi import Printer\n",
        "import pandas as pd\n",
        "\n",
        "colunas = ['Numero_ent', 'Contexto anterior', 'Ocorrencia','Contexto Seguinte', 'Contexto']\n",
        "linhas = []\n",
        "\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "\n",
        "nomes_arq = !ls '/content/drive/MyDrive/LinguagemCorporificada2023'\n",
        "\n",
        "for nome in nomes_arq:\n",
        "  nome_refatorado = nome.replace(\"'\", \"\").strip() # remove leading/trailing spaces\n",
        "  arq =f'/content/drive/MyDrive/LinguagemCorporificada2023/{nome_refatorado}'\n",
        "  corpus = open(arq).read()\n",
        "  doc = nlp(corpus)\n",
        "  numero_ent = extrai_num_ent(nome)\n",
        "\n",
        "  matcher = Matcher(vocab=nlp.vocab)\n",
        "  detso = [{'LEMMA': {'NOT_IN': ['meu','teu', 'seu', 'nosso']}},\n",
        "           {'POS': 'DET', 'MORPH':{'IS_SUPERSET': ['PronType=Prs']}},\n",
        "           {'POS': 'NOUN'}]\n",
        "  matcher.add('detso', [detso])\n",
        "  detrex = matcher(doc, as_spans=True)\n",
        "  matches = matcher(doc)\n",
        "\n",
        "  match = Printer()\n",
        "  for match_id, start, end in matches:\n",
        "    ocorrencia = doc[start:end]\n",
        "    contexto = doc[start-20:end+20]\n",
        "    contexto_parte1 = doc[start-20:start]\n",
        "    contexto_parte2 = doc[end: end+20]\n",
        "    linhas.append ([numero_ent, contexto_parte1, ocorrencia,contexto_parte2, contexto])\n",
        "\n",
        "dataframe = pd.DataFrame(linhas, columns = colunas)\n",
        "dataframe.to_excel(\"det2023.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPOu_ls22p6Z"
      },
      "source": [
        "## 5.2 Pronomes pessoais de 2PS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zcvbt2q2tsr"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from wasabi import Printer\n",
        "import pandas as pd\n",
        "\n",
        "colunas = ['Numero_ent', 'Contexto anterior', 'Ocorrencia','Contexto Seguinte', 'Contexto']\n",
        "linhas = []\n",
        "\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "\n",
        "nomes_arq = !ls '/content/drive/MyDrive/LinguagemCorporificada2023'\n",
        "\n",
        "for nome in nomes_arq:\n",
        "  nome_refatorado = nome.replace(\"'\", \"\").strip() # remove leading/trailing spaces\n",
        "  arq =f'/content/drive/MyDrive/LinguagemCorporificada2023/{nome_refatorado}'\n",
        "  corpus = open(arq).read()\n",
        "  doc = nlp(corpus)\n",
        "  numero_ent = extrai_num_ent(nome)\n",
        "  matcher = Matcher(vocab=nlp.vocab)\n",
        "  detso = [{'ORTH': {'IN': ['você', 'cê', 'tu']}}, {'POS': 'VERB', 'MORPH': {'IS_SUPERSET': ['VerbForm=Fin']}}]\n",
        "  inte = [{'ORTH': {'IN': ['você', 'cê', 'tu']}}, {}, {'POS': 'VERB', 'MORPH': {'IS_SUPERSET': ['VerbForm=Fin']}}] # com material interveniente\n",
        "\n",
        "  matcher.add('detso', [detso])\n",
        "  matcher.add('inte', [inte])\n",
        "  detrex = matcher(doc, as_spans=True)\n",
        "  matches = matcher(doc)\n",
        "  match = Printer()\n",
        "  for match_id, start, end in matches:\n",
        "        ocorrencia = doc[start:end]\n",
        "        contexto = doc[start-20:end+20]\n",
        "        contexto_parte1 = doc[start-20:start]\n",
        "        contexto_parte2 = doc[end: end+20]\n",
        "        linhas.append ([numero_ent, contexto_parte1, ocorrencia,contexto_parte2, contexto])\n",
        "\n",
        "dataframe = pd.DataFrame(linhas, columns = colunas)\n",
        "dataframe.to_excel(\"pro2023.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqj3Akdo6xzS"
      },
      "source": [
        "## 5.3 Clíticos de 2PS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui4pl-Og6wXv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from wasabi import Printer\n",
        "import pandas as pd\n",
        "\n",
        "colunas = ['Numero_ent', 'Contexto anterior', 'Ocorrencia','Contexto Seguinte', 'Contexto']\n",
        "linhas = []\n",
        "\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "\n",
        "nomes_arq = !ls '/content/drive/MyDrive/LinguagemCorporificada2023'\n",
        "\n",
        "for nome in nomes_arq:\n",
        "  nome_refatorado = nome.replace(\"'\", \"\").strip() # remove leading/trailing spaces\n",
        "  arq =f'/content/drive/MyDrive/LinguagemCorporificada2023/{nome_refatorado}'\n",
        "  corpus = open(arq).read()\n",
        "  doc = nlp(corpus)\n",
        "  numero_ent = extrai_num_ent(nome)\n",
        "  matcher = Matcher(vocab=nlp.vocab)\n",
        "  matcher = Matcher(vocab=nlp.vocab)\n",
        "  detso = [{'ORTH': {'IN': ['te', 'lhe']}}, {'POS': 'VERB'}]\n",
        "  clitc= [{'POS': 'VERB'}, {'ORTH': {'IN': ['te', 'lhe']}}]\n",
        "  encli= [{'POS': 'VERB'}, {'IS_PUNCT': True}, {'ORTH': {'IN': ['te', 'lhe']}}]\n",
        "\n",
        "  matcher.add('detso', [detso])\n",
        "  matcher.add('clitc', [clitc])\n",
        "  matcher.add('encli', [encli])\n",
        "  detrex = matcher(doc, as_spans=True)\n",
        "  matches = matcher(doc)\n",
        "  match = Printer()\n",
        "  for match_id, start, end in matches:\n",
        "        ocorrencia = doc[start:end]\n",
        "        contexto = doc[start-20:end+20]\n",
        "        contexto_parte1 = doc[start-20:start]\n",
        "        contexto_parte2 = doc[end: end+20]\n",
        "        linhas.append ([numero_ent, contexto_parte1, ocorrencia,contexto_parte2, contexto])\n",
        "\n",
        "dataframe = pd.DataFrame(linhas, columns = colunas)\n",
        "dataframe.to_excel(\"cli2023.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ecXiS-Z_MQM"
      },
      "source": [
        "## 5.4 Possessivos de 2PS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEiaDT219Yit"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from wasabi import Printer\n",
        "import pandas as pd\n",
        "\n",
        "colunas = ['Numero_ent', 'Contexto anterior', 'Ocorrencia','Contexto Seguinte', 'Contexto']\n",
        "linhas = []\n",
        "\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "\n",
        "nomes_arq = !ls '/content/drive/MyDrive/LinguagemCorporificada2023'\n",
        "\n",
        "for nome in nomes_arq:\n",
        "  nome_refatorado = nome.replace(\"'\", \"\").strip() # remove leading/trailing spaces\n",
        "  arq =f'/content/drive/MyDrive/LinguagemCorporificada2023/{nome_refatorado}'\n",
        "  corpus = open(arq).read()\n",
        "  doc = nlp(corpus)\n",
        "  numero_ent = extrai_num_ent(nome)\n",
        "\n",
        "  matcher = Matcher(vocab=nlp.vocab)\n",
        "  pre = [{\"TEXT\": {\"IN\":[\"seu\", \"sua\", \"seus\", \"suas\", \"teu\", \"tua\", \"teus\", \"tuas\"]}}, {\"POS\": \"NOUN\"}]\n",
        "  pos = [{\"POS\": \"NOUN\"}, {\"TEXT\": {\"IN\":[\"seu\", \"sua\", \"seus\", \"suas\", \"teu\", \"tua\", \"teus\", \"tuas\"]}}]\n",
        "\n",
        "  matcher.add('pre', [pre])\n",
        "  matcher.add('pos', [pos])\n",
        "  detrex = matcher(doc, as_spans=True)\n",
        "  matches = matcher(doc)\n",
        "  match = Printer()\n",
        "  for match_id, start, end in matches:\n",
        "    ocorrencia = doc[start:end]\n",
        "    contexto = doc[start-20:end+20]\n",
        "    contexto_parte1 = doc[start-20:start]\n",
        "    contexto_parte2 = doc[end: end+20]\n",
        "    linhas.append ([numero_ent, contexto_parte1, ocorrencia,contexto_parte2, contexto])\n",
        "\n",
        "dataframe = pd.DataFrame(linhas, columns = colunas)\n",
        "dataframe.to_excel(\"pos2023.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}